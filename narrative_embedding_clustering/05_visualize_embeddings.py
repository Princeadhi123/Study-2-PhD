import sys
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.manifold import TSNE

from config import OUTPUT_DIR, STUDENT_CLUSTERS_PATH, make_versioned_filename, DERIVED_FEATURES_PATH


def _load_embeddings():

    emb_filename = make_versioned_filename("embeddings.npy")
    index_filename = make_versioned_filename("embeddings_index.csv")
    emb_path = OUTPUT_DIR / emb_filename
    index_path = OUTPUT_DIR / index_filename
    if not emb_path.exists() or not index_path.exists():
        raise SystemExit("Embeddings or index not found. Run 02_compute_embeddings.py first.")
    X = np.load(emb_path)
    index_df = pd.read_csv(index_path)
    return X, index_df


def _load_clusters():

    narrative_clusters_filename = make_versioned_filename("narrative_clusters.csv")
    narrative_clusters_path = OUTPUT_DIR / narrative_clusters_filename
    if not narrative_clusters_path.exists():
        raise SystemExit("Missing narrative_clusters.csv. Run 03_cluster_embeddings.py first.")
    nar_clusters = pd.read_csv(narrative_clusters_path)

    stud_clusters = pd.read_csv(STUDENT_CLUSTERS_PATH)

    return nar_clusters, stud_clusters


def _prepare_coords(index_df: pd.DataFrame, nar_clusters: pd.DataFrame, stud_clusters: pd.DataFrame) -> pd.DataFrame:
    """Merge embedding index with narrative and numeric cluster labels.

    This does *not* compute any projection; projections are computed separately
    and added as columns when plotting.
    """
    coords = index_df.merge(nar_clusters[["IDCode", "narrative_best_label"]], on="IDCode", how="left")
    coords = coords.merge(
        stud_clusters[["IDCode", "gmm_bic_best_label", "gmm_aic_best_label"]], on="IDCode", how="left"
    )
    return coords


def _plot_scatter(
    coords: pd.DataFrame,
    color_col: str,
    title: str,
    filename: str,
    x_col: str,
    y_col: str,
    x_label: str,
    y_label: str,
) -> None:
    try:
        import matplotlib.pyplot as plt
    except ImportError as exc:
        raise SystemExit(
            "matplotlib is required for visualization. Install it with:\n"
            "pip install matplotlib"
        ) from exc

    fig, ax = plt.subplots(figsize=(8, 6))

    labels = sorted(coords[color_col].dropna().unique())
    scatter = ax.scatter(
        coords[x_col],
        coords[y_col],
        c=coords[color_col],
        cmap="tab10",
        s=15,
        alpha=0.8,
    )

    handles, _ = scatter.legend_elements(prop="colors")
    legend_labels = [f"{color_col} = {int(l)}" for l in labels]
    ax.legend(handles, legend_labels, title=color_col, bbox_to_anchor=(1.05, 1), loc="upper left")

    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)
    ax.set_title(title)
    ax.grid(True, alpha=0.2)

    figures_dir = OUTPUT_DIR / "figures"
    figures_dir.mkdir(parents=True, exist_ok=True)
    out_path = figures_dir / filename
    fig.tight_layout()
    fig.savefig(out_path, dpi=200)
    plt.close(fig)

    print(f"Saved {title} plot to {out_path}")


def _plot_pca_loadings(coords_pca: pd.DataFrame) -> None:
    """Calculates and plots the correlation of PC1/PC2 with numeric features."""
    if not DERIVED_FEATURES_PATH.exists():
        print(f"Derived features not found at {DERIVED_FEATURES_PATH}, skipping PCA loadings heatmap.")
        return

    # Load numeric features
    df_features = pd.read_csv(DERIVED_FEATURES_PATH)
    
    # Recalculate derived columns (consistent with 01_build_narratives)
    with np.errstate(divide="ignore", invalid="ignore"):
        df_features["accuracy"] = df_features["total_correct"] / df_features["n_items"].replace(0, np.nan)
        std_rt = np.sqrt(df_features["var_rt"].clip(lower=0.0))
        df_features["rt_cv"] = std_rt / df_features["avg_rt"].replace(0, np.nan)

    # Select relevant numeric columns
    numeric_cols = [
        "total_correct",
        "total_incorrect",
        "accuracy",
        "consecutive_correct_rate",
        "longest_incorrect_streak",
        "response_variance",
        "longest_correct_streak",
        "var_rt",
        "rt_cv",
        "avg_rt"
    ]
    
    # Merge with PCA coordinates
    # coords_pca has "IDCode", "dim1" (PC1), "dim2" (PC2), potentially "dim3" (PC3)
    pca_cols = [c for c in coords_pca.columns if c.startswith("dim")]
    merged = coords_pca.merge(df_features[["IDCode"] + numeric_cols], on="IDCode", how="inner")
    
    if merged.empty:
        return

    # Compute correlations (loadings)
    cols_to_corr = pca_cols + numeric_cols
    correlations = merged[cols_to_corr].corr(method="spearman")
    loadings = correlations.loc[numeric_cols, pca_cols]
    
    # Rename PC columns dynamically
    pc_names = [f"PC{i+1}" for i in range(len(pca_cols))]
    loadings.columns = pc_names
    
    # Drop rows that are all NaN (e.g. n_items if constant)
    loadings = loadings.dropna(how="all")

    # Transpose for horizontal representation (PCs on Y-axis, Features on X-axis)
    loadings = loadings.T

    # Rename columns for better readability
    feature_map = {
        "total_correct": "Total Correct",
        "total_incorrect": "Total Incorrect",
        "accuracy": "Accuracy",
        "consecutive_correct_rate": "Consec. Correct Rate",
        "longest_incorrect_streak": "Max Incorrect Streak",
        "response_variance": "Response Variance",
        "longest_correct_streak": "Max Correct Streak",
        "var_rt": "RT Variance",
        "rt_cv": "RT Coeff. Variation",
        "avg_rt": "Avg Response Time"
    }
    loadings = loadings.rename(columns=feature_map)

    # Plot Heatmap
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
    except ImportError:
        print("seaborn not installed, skipping heatmap.")
        return

    # Wider figure for horizontal layout
    fig, ax = plt.subplots(figsize=(12, 4))
    sns.heatmap(
        loadings, 
        annot=True, 
        cmap="coolwarm", 
        center=0, 
        vmin=-1, 
        vmax=1, 
        ax=ax, 
        fmt=".2f",
        linewidths=0.5,
        cbar_kws={"label": "Spearman Correlation"}
    )
    ax.set_title("PCA Loadings: Feature Contributions to Axes", fontsize=14, pad=15)
    
    # Rotate x-axis labels for readability
    plt.xticks(rotation=45, ha="right")
    plt.yticks(rotation=0)

    figures_dir = OUTPUT_DIR / "figures"
    figures_dir.mkdir(parents=True, exist_ok=True)
    out_path = figures_dir / make_versioned_filename("pca_loadings_heatmap.png")
    
    fig.tight_layout()
    fig.savefig(out_path, dpi=300)
    plt.close(fig)
    print(f"Saved PCA loadings heatmap to {out_path}")


def _plot_narrative_k_selection() -> None:
    results_filename = make_versioned_filename("model_results_narrative.csv")
    results_path = OUTPUT_DIR / results_filename
    if not results_path.exists():
        return

    df = pd.read_csv(results_path)
    required_cols = {"K", "covariance_type", "bic"}
    if not required_cols.issubset(df.columns) or df.empty:
        return

def _plot_metric_selection(df: pd.DataFrame, metric: str, title_suffix: str, filename_suffix: str) -> None:
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        return

    fig, ax = plt.subplots(figsize=(8, 6))

    # Filter out infinite values for plotting
    df_clean = df[np.isfinite(df[metric])].copy()
    
    if df_clean.empty:
        print(f"No valid {metric} values to plot.")
        plt.close(fig)
        return

    for cov, sub in df_clean.groupby("covariance_type"):
        sub_sorted = sub.sort_values("K")
        ax.plot(sub_sorted["K"], sub_sorted[metric], marker="o", label=cov)

    best_idx = df_clean[metric].idxmin()
    best_row = df_clean.loc[best_idx]
    best_k = int(best_row["K"])
    best_cov = str(best_row["covariance_type"])
    best_val = float(best_row[metric])
    ax.axvline(best_k, color="red", linestyle="--", alpha=0.7)

    ax.set_xlabel("Number of narrative clusters (K)")
    ax.set_ylabel(metric.upper())
    ax.set_title(f"Narrative GMM model selection by {title_suffix} (best K={best_k}, cov={best_cov})")
    ax.grid(True, alpha=0.2)
    ax.legend(title="covariance_type")

    figures_dir = OUTPUT_DIR / "figures"
    figures_dir.mkdir(parents=True, exist_ok=True)
    out_path = figures_dir / make_versioned_filename(f"narrative_gmm_{filename_suffix}.png")
    fig.tight_layout()
    fig.savefig(out_path, dpi=200)
    plt.close(fig)

    print(
        "Selected narrative GMM by {metric}: K={k}, cov={cov}, {metric}={val:.2f}".format(
            metric=metric.upper(), k=best_k, cov=best_cov, val=best_val
        )
    )
    print(f"Saved narrative GMM {metric.upper()} plot to {out_path}")


def _plot_narrative_k_selection() -> None:
    # Load the latest model results
    pattern = "model_results_narrative*.csv"
    files = sorted(OUTPUT_DIR.glob(pattern), key=lambda f: f.stat().st_mtime, reverse=True)
    if not files:
        print("No narrative model results found. Run 03_cluster_embeddings.py first.")
        return
    
    latest_file = files[0]
    print(f"Loading model results from: {latest_file.name}")
    df = pd.read_csv(latest_file)
    
    if "bic" in df.columns:
        _plot_metric_selection(df, "bic", "BIC", "bic_vs_k")
    
    if "aicc" in df.columns:
        _plot_metric_selection(df, "aicc", "AICc", "aicc_vs_k")


def main() -> None:
    _plot_narrative_k_selection()
    try:
        X, index_df = _load_embeddings()
        nar_clusters, stud_clusters = _load_clusters()
        coords = _prepare_coords(index_df, nar_clusters, stud_clusters)
        
        # Additional visualizations could be added here
        
    except Exception as e:
        print(f"Visualization error: {e}")


    # --- PCA projection (baseline, with 3 components to capture Timing) ---
    pca = PCA(n_components=3, random_state=42)
    X_pca = pca.fit_transform(X)
    coords_pca = coords.copy()
    coords_pca["dim1"] = X_pca[:, 0]
    coords_pca["dim2"] = X_pca[:, 1]
    coords_pca["dim3"] = X_pca[:, 2]

    # Plot PCA Loadings Heatmap (Correlation with Numeric Features)
    _plot_pca_loadings(coords_pca)

    # Plot 1: Standard PC1 vs PC2 (Intensity vs Performance)
    _plot_scatter(
        coords_pca,
        color_col="narrative_best_label",
        title="Narrative GMM-BIC clusters (PCA: Intensity vs Performance)",
        filename=make_versioned_filename("embeddings_pca_PC1_vs_PC2.png"),
        x_col="dim1",
        y_col="dim2",
        x_label="PC1 (Behavioral Intensity)",
        y_label="PC2 (Academic Performance)",
    )

    # Plot 2: PC2 vs PC3 (Performance vs Timing) - The "Cluster Separator"
    _plot_scatter(
        coords_pca,
        color_col="narrative_best_label",
        title="Narrative GMM-BIC clusters (PCA: Performance vs Speed)",
        filename=make_versioned_filename("embeddings_pca_PC2_vs_PC3.png"),
        x_col="dim2",
        y_col="dim3",
        x_label="PC2 (Academic Performance)",
        y_label="PC3 (Speed & Consistency)",
    )

    # Keep the numeric cluster comparisons on PC1/PC2 for reference
    _plot_scatter(
        coords_pca,
        color_col="gmm_bic_best_label",
        title="Numeric GMM-BIC clusters (PCA: Intensity vs Performance)",
        filename=make_versioned_filename("embeddings_pca_gmm_bic_clusters.png"),
        x_col="dim1",
        y_col="dim2",
        x_label="PC1 (Behavioral Intensity)",
        y_label="PC2 (Academic Performance)",
    )

    _plot_scatter(
        coords_pca,
        color_col="gmm_aic_best_label",
        title="Numeric GMM-AIC clusters (embedding PCA)",
        filename=make_versioned_filename("embeddings_pca_gmm_aic_clusters.png"),
        x_col="dim1",
        y_col="dim2",
        x_label="PC1 (narrative embeddings)",
        y_label="PC2 (narrative embeddings)",
    )

    # --- UMAP projection (narrative clusters only) ---
    try:
        import umap

        umap_model = umap.UMAP(n_components=2, random_state=42)
        X_umap = umap_model.fit_transform(X)
        coords_umap = coords.copy()
        coords_umap["dim1"] = X_umap[:, 0]
        coords_umap["dim2"] = X_umap[:, 1]

        _plot_scatter(
            coords_umap,
            color_col="narrative_best_label",
            title="Narrative GMM-BIC clusters (embedding UMAP)",
            filename=make_versioned_filename("embeddings_umap_narrative_clusters.png"),
            x_col="dim1",
            y_col="dim2",
            x_label="UMAP1 (narrative embeddings)",
            y_label="UMAP2 (narrative embeddings)",
        )
    except ImportError:
        print(
            "umap-learn is not installed; skipping UMAP plot. "
            "Install it with: pip install umap-learn"
        )

    # --- t-SNE projection (narrative clusters only) ---
    tsne = TSNE(n_components=2, random_state=42, init="pca", learning_rate="auto")
    X_tsne = tsne.fit_transform(X)
    coords_tsne = coords.copy()
    coords_tsne["dim1"] = X_tsne[:, 0]
    coords_tsne["dim2"] = X_tsne[:, 1]

    _plot_scatter(
        coords_tsne,
        color_col="narrative_best_label",
        title="Narrative GMM-BIC clusters (embedding t-SNE)",
        filename=make_versioned_filename("embeddings_tsne_narrative_clusters.png"),
        x_col="dim1",
        y_col="dim2",
        x_label="t-SNE1 (narrative embeddings)",
        y_label="t-SNE2 (narrative embeddings)",
    )

    # --- LDA projection (supervised by narrative clusters) ---
    lda = LinearDiscriminantAnalysis(n_components=2)
    y = coords["narrative_best_label"].to_numpy()
    X_lda = lda.fit_transform(X, y)
    coords_lda = coords.copy()
    coords_lda["dim1"] = X_lda[:, 0]
    coords_lda["dim2"] = X_lda[:, 1]

    _plot_scatter(
        coords_lda,
        color_col="narrative_best_label",
        title="Narrative GMM-BIC clusters (embedding LDA)",
        filename=make_versioned_filename("embeddings_lda_narrative_clusters.png"),
        x_col="dim1",
        y_col="dim2",
        x_label="LDA1 (narrative embeddings)",
        y_label="LDA2 (narrative embeddings)",
    )


if __name__ == "__main__":
    main()
